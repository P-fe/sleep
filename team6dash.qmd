---
title: '수면 효율성 분석'
title-slide-attributes: 
  data-background-image: sleep.png
  data-background-opacity: "0.4"
author: '6조 구교빈, 김윤희, 조익현, 신인철'
subtitle: '변수별 수면 패턴 분석' 
format: 
  revealjs:
    theme: default
    scrollable: true
    slide-number: true
    toc: False
    toc-title: "목차"
    transition: fade
    footer: '6조'
    width: 1280         # 💡 슬라이드 너비 확장
    height: 800         # 💡 슬라이드 높이 확장
    margin: 0.05        # 💡 슬라이드 여백 축소 (더 넓게 사용)
css: style.css      # 커스텀 CSS 추가
---

## 📌 목차 {.scrollable}

#### 🟦 서론
- 주제 선정 이유  
- 데이터 정의  
- 데이터 전처리  
- 데이터 EDA   

#### 🟩 본론
- 상관관계 분석  
- 독립 변수 선택 이유 / Deep sleep 제외 이유
- 독립변수 4개 요인  
  - 운동빈도별 Light sleep %, Sleep Efficiency  
  - 흡연여부별 Light sleep %, Sleep Efficiency    
  - 음주여부별 Light sleep %, Sleep Efficiency  
  - 카페인 선택 이유 
- 회귀 모델링  
  - 모델 선정 과정  
  - 최종 모델  

#### 🟥 결론


# 서론

## 주제선정이유

:::{.columns}

::: {.column width="50%"}
<br><br><br><br>  
안녕하세요, 여러분!<br>
한 주 동안 프로젝트 하시느라 많이 피곤하셨죠?<br>
혹시 잠이 부족하진 않으셨나요...?<br>
아니면 지금... 졸고 계신 건 아니시죠?? 😄<br>
:::

::: {.column width="50%"}
![](students.png){width=100%}
:::

:::

---

 ⟶강사님의 질문에 대한 **응답성 저하**  
 ⟶수면 효율 향상을 위해 Ls미래원과 우리는 **어떠한 노력**을 해야할까?

<div style="text-align: center;">
  <img src="students_2.png" style="width: 80%;" />
</div>


---

## 데이터 정의

| 구분             | 요약 설명 |
|------------------|-----------|
| **REM Sleep**      | 학습과 기억을 돕고, 생생한 꿈이 나타나는 뇌 활성 수면 단계 |
| **Deep Sleep**     | 뇌 회복과 성장호르몬 분비가 일어나는 가장 깊은 수면 단계 |
| **Light Sleep**    | 수면의 절반 이상을 차지하며, 깊은 수면으로 넘어가기 위한 준비 단계 |
| **Sleep Efficiency** | 실제 수면 시간 ÷ 침대에 누운 시간으로 수면의 질을 평가하는 지표 |


| 변수명 (영문)             | 변수명 (한글)         | 데이터 타입 (영문) | 데이터 타입 (한글)     |
|---------------------------|------------------------|---------------------|-------------------------|
| ID                        | ID                     | int64               | 정수형                  |
| Age                       | 나이                   | int64               | 정수형                  |
| Gender                    | 성별                   | object              | 문자형 (범주형 포함)    |
| Bedtime                   | 취침 시간              | object              | 문자형 (범주형 포함)    |
| Wakeup time               | 기상 시간              | object              | 문자형 (범주형 포함)    |
| Sleep duration            | 수면 시간              | float64             | 실수형                  |
| Sleep efficiency          | 수면 효율              | float64             | 실수형                  |
| REM sleep percentage      | REM 수면 비율          | int64               | 정수형                  |
| Deep sleep percentage     | 깊은 수면 비율         | int64               | 정수형                  |
| Light sleep percentage    | 얕은 수면 비율         | int64               | 정수형                  |
| Awakenings                | 깬 횟수                | float64             | 실수형                  |
| Caffeine consumption      | 카페인 섭취량          | float64             | 실수형                  |
| Alcohol consumption       | 알코올 섭취량          | float64             | 실수형                  |
| Smoking status            | 흡연 여부              | object              | 문자형 (범주형 포함)    |
| Exercise frequency        | 운동 빈도              | float64             | 실수형   


## 데이터 전처리

```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import shapiro
from statsmodels.stats.diagnostic import het_breuschpagan
from scipy.stats import kruskal
from scipy.stats import chi2_contingency
from sklearn.linear_model import LinearRegression
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
df = pd.read_csv('Sleep_Efficiency.csv')
```

```{python}
#| echo: true


# 1. 'Awakenings'와 'Exercise frequency' 최빈값 계산
awakening_mode = df['Awakenings'].mode()[0]
exercise_mode = df['Exercise frequency'].mode()[0]
Alcohol_mode = df['Alcohol consumption'].mode()[0]
Caffeine_mode = df['Caffeine consumption'].mode()[0]

# 2. 해당 컬럼의 결측치 최빈값으로 대체
df['Awakenings'] = df['Awakenings'].fillna(awakening_mode)
df['Exercise frequency'] = df['Exercise frequency'].fillna(exercise_mode)
df['Alcohol consumption'] = df['Alcohol consumption'].fillna(Alcohol_mode)
df['Caffeine consumption'] = df['Caffeine consumption'].fillna(Caffeine_mode)

```


```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import shapiro
from statsmodels.stats.diagnostic import het_breuschpagan
from scipy.stats import kruskal
from scipy.stats import chi2_contingency



df = pd.read_csv('Sleep_Efficiency.csv')

# 1. 'Awakenings'와 'Exercise frequency' 최빈값 계산
awakening_mode = df['Awakenings'].mode()[0]
exercise_mode = df['Exercise frequency'].mode()[0]

# 2. 해당 컬럼의 결측치 최빈값으로 대체
df['Awakenings'] = df['Awakenings'].fillna(awakening_mode)
df['Exercise frequency'] = df['Exercise frequency'].fillna(exercise_mode)

# 3. 나머지 결측치는 0으로 대체
df = df.fillna(0)

# 결측치 최종 확인
missing_summary = df.isnull().sum()

awakening_mode, exercise_mode, missing_summary

df['Bedtime'] = pd.to_datetime(df['Bedtime'], errors='coerce')


df['bed_halfhour'] = df['Bedtime'].dt.hour + (df['Bedtime'].dt.minute >= 30) * 0.5
df['bed_halfhour'].value_counts().sort_index()

df.head(5)

```



## EDA(데이터 현황)

### 운동 빈도와 잠의 관계

:::{.column width="50%"}

```{python}
Exer_frq = df['Exercise frequency'].unique()
Exer_frq.sort()
# print('운동빈도 수 : ', Exer_frq)
Ef_Lsp = df.groupby('Exercise frequency')['Light sleep percentage'].mean()
Ef_SE = df.groupby('Exercise frequency')['Sleep efficiency'].mean()

# 운동빈도에 따른 light sleep 그래프
norm_values = (Ef_Lsp .values - min(Ef_Lsp .values)) / (max(Ef_Lsp .values) - min(Ef_Lsp .values))
colors = [(0.56, 0.93, 0.56, alpha) for alpha in norm_values]
plt.figure(figsize=(5, 5))
plt.bar(Ef_Lsp .index, Ef_Lsp .values, color=colors, edgecolor='black')
plt.title('Light sleep by E.F')
plt.xlabel('Frequency')
plt.ylabel('Light sleep')
plt.ylim(10,35)
plt.show()
```

:::

:::{.column width="50%"}

```{python}
norm_values = (Ef_SE.values - min(Ef_SE.values)) / (max(Ef_SE.values) - min(Ef_SE.values))
colors = [(0.56, 0.93, 0.56, alpha) for alpha in norm_values]
plt.figure(figsize=(5, 5))
plt.bar(Ef_SE.index, Ef_SE.values, color=colors, edgecolor='black')
plt.title('Sleep Efficiency by E.F')
plt.xlabel('Frequency')
plt.ylabel('Sleep Efficiency')
plt.ylim(0.5,1)
plt.show()
```

:::

---

### 음주 여부와 잠의 관계 

:::{.column width="50%"}

```{python}

# 2. Alcohol Group 컬럼 생성 (0.0 vs Other)
def alcohol_binary_group(val):
    if val == 0.0:
        return '0.0'
    else:
        return 'Other'
df['Alcohol consumption'].unique()
df['Alcohol Binary Group'] = df['Alcohol consumption'].apply(alcohol_binary_group)
# 취한 사람과 안취한 사람간의 데이터 구분

non_drink = df[df['Alcohol Binary Group'] == '0.0' ]
drink =  df[df['Alcohol Binary Group'] == 'Other' ]

# 알콜 기준 light sleep percentage

# 2. Alcohol 그룹 나누기: 0.0 vs Other
def alcohol_binary_group(val):
    if val == 0.0:
        return '0.0'
    else:
        return 'Other'

df['Alcohol Binary Group'] = df['Alcohol consumption'].apply(alcohol_binary_group)

# 3. 그룹별 평균 Light sleep percentage 계산
light_sleep_means = df.groupby('Alcohol Binary Group')['Light sleep percentage'].mean()

# 4. 막대 그래프 그리기
plt.figure(figsize=(6, 5))
light_sleep_means.loc[['0.0', 'Other']].plot(
    kind='bar',
    color=['mediumaquamarine', 'indianred'],
    edgecolor='black'
)
plt.title("Average Light Sleep Percentage by Alcohol Group (0.0 vs Other)")
plt.xlabel("Alcohol Consumption Group")
plt.ylabel("Light Sleep Percentage")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()
```

:::

:::{.column width="50%"}


```{python}
# 4. 막대 그래프 시각화
# 3. 그룹별 Sleep efficiency 평균 계산
group_means = df.groupby('Alcohol Binary Group')['Sleep efficiency'].mean()
plt.figure(figsize=(6, 5))
group_means.loc[['0.0', 'Other']].plot(
    kind='bar',
    color=['royalblue', 'lightcoral'],
    edgecolor='black'
)
plt.title("Average Sleep Efficiency by Alcohol Group (0.0 vs Other)")
plt.xlabel("Alcohol Consumption Group")
plt.ylabel("Sleep Efficiency")
plt.ylim(0, 1)
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()
```

:::


# 본론

## 상관관계 그래프

```{python}


# 수치형 변수만 선택
numeric_df = df.select_dtypes(include='number')
# 상관계수 행렬 계산
corr_matrix = numeric_df.corr()
# 수치형 변수만 선택
numeric_df = df.select_dtypes(include='number')
# 상관계수 행렬 계산
corr_matrix = numeric_df.corr()
# 히트맵 시각화
plt.figure(figsize=(10, 7))
sns.heatmap(corr_matrix, 
            annot=True,         # 셀 안에 숫자 표시
            fmt=".2f",          # 소수점 둘째자리까지
            cmap="coolwarm",    # 색상 맵
            square=True, 
            linewidths=0.5)
plt.title("Correlation matrix heatmap of numerical features")
plt.tight_layout()
plt.grid(False)
plt.show()
```

---


## 독립 변수 선택 이유 / Deep sleep 제외 이유


```{python}
X = df[[
    'Caffeine consumption',
    'Alcohol consumption',
    'Exercise frequency',
    'Awakenings',
    'REM sleep percentage',
    'Deep sleep percentage',
    'Light sleep percentage'
]]
y = df['Sleep efficiency']
# 상수항 추가
X_const = sm.add_constant(X)
# OLS 회귀 모델 적합
model = sm.OLS(y, X_const).fit()
# model.summary()

```


| 변수                   | 계수 (β)     | p-value   | 유의성 | 해석                             |
|------------------------|--------------|-----------|--------|----------------------------------|
| Caffeine consumption   | +0.000024    | 0.809     | ❌     | 영향 없음                        |
| Alcohol consumption    | -0.0056      | 0.005     | ✅     | 알코올 ↑ → 수면 효율 ↓          |
| Exercise frequency     | +0.0050      | 0.021     | ✅     | 운동 ↑ → 수면 효율 ↑            |
| Awakenings             | -0.0308      | <0.001    | ✅     | 자주 깰수록 수면 효율 ↓         |
| REM sleep %            | +0.0035      | <0.001    | ✅     | REM ↑ → 수면 효율 ↑             |
| Deep sleep %           | -0.0006      | 0.643     | ❌     | 영향 없음                        |
| Light sleep %          | -0.0068      | <0.001    | ✅     | Light ↑ → 수면 효율 ↓           |

![](abc.png){width=100%}

Light sleep을 선택한 이유(다중공산성): Deep sleep을 뺀이유는 개별 상관에서는 유의했지만
회귀에서는 다른 변수들과 겹치는 영향(공산성) 때문에 유의하지 않게 나올수 있음

---

## 독립변수 4개 요인

### 분석 대상 및 방법 순서

- 분석 대상 순서
    - 운동 빈도 Exercise frequency (0회 ~ 5회)
    - 흡연 여부 Smoker / Non_Smoker
    - 음주 여부 Other  / 0.0
    - 카페인 여부 

- 분석 방법 순서
    - 정규성 검정 그래프
    - 정규성 검정 수치
    - 유의성 검정


---

### 첫번째 : 운동빈도별 Light sleep %

- 정규성 검정 

```{python}
Ef_0 = df[df['Exercise frequency']== 0]
Ef_1 = df[df['Exercise frequency']== 1]
Ef_2 = df[df['Exercise frequency']== 2]
Ef_3 = df[df['Exercise frequency']== 3]
Ef_4 = df[df['Exercise frequency']== 4]
Ef_5 = df[df['Exercise frequency']== 5]


fig, axes = plt.subplots(2, 3, figsize=(15, 8))
axes = axes.flatten()
for i in range(6):
    sns.kdeplot(
        df[df['Exercise frequency'] == i]['Light sleep percentage'].dropna(),
        ax=axes[i],
        fill=True,
        color=sns.color_palette("tab10")[i],
    )
    axes[i].set_title(f"Exercise {i}")
    axes[i].set_xlim(0, 100)
    axes[i].grid(True, linestyle='--', alpha=0.3)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()
```

```{python}
Ef_0_l = shapiro(Ef_0['Light sleep percentage'])
Ef_1_l = shapiro(Ef_1['Light sleep percentage'])
Ef_2_l = shapiro(Ef_2['Light sleep percentage'])
Ef_3_l = shapiro(Ef_3['Light sleep percentage'])
Ef_4_l = shapiro(Ef_4['Light sleep percentage'])
Ef_5_l = shapiro(Ef_5['Light sleep percentage'])

# print('운동 0번과 light sleep 정규성 검정', Ef_0_l.pvalue )
# print('운동 1번과 light sleep 정규성 검정', Ef_1_l.pvalue )
# print('운동 2번과 light sleep 정규성 검정', Ef_2_l.pvalue )
# print('운동 3번과 light sleep 정규성 검정', Ef_3_l.pvalue )
# print('운동 4번과 light sleep 정규성 검정', Ef_4_l.pvalue )
# print('운동 5번과 light sleep 정규성 검정', Ef_5_l.pvalue )
# print("모든값이 매우 작은값이다, 즉 귀무가설을 기각하고 정규분포를 따르지 않는다.")
```


| 검정 항목            | 귀무가설(H₀)                         | p-value    | 해석                 | 가정 만족 여부 |
|---------------------|------------------------------------|------------|----------------------|----------------|
| 운동 횟수 0번        | 이 변수는 정규분포를 따른다.            | 6.49e-12   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 1번        | 이 변수는 정규분포를 따른다.            | 3.79e-13   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 2번        | 이 변수는 정규분포를 따른다.            | 8.61e-10   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 3번        | 이 변수는 정규분포를 따른다.            | 5.54e-14   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 4번        | 이 변수는 정규분포를 따른다.            | 3.07e-09   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 5번        | 이 변수는 정규분포를 따른다.            | 2.15e-06   | 정규분포를 따르지 않는다. | ❌            |

---



- 유의성 검정


```{python}
result_k1 = kruskal(Ef_0['Light sleep percentage'], Ef_1['Light sleep percentage']
                 ,Ef_2['Light sleep percentage'],Ef_3['Light sleep percentage']
                 ,Ef_4['Light sleep percentage'],Ef_5['Light sleep percentage']) 
# print('운동횟수에 따른 Light sleep 유의성 검정 : ', result_k1.pvalue.round(5))
# print('pvalue 값이 0.0003로 작기때문에 그룹간 유의한 차이가 있다.')
```

- **Kruskal-Wallis H 검정 사용**
    - 크루스칼-왈리스 검정 P_value = 0.0003
    - P_value가 매우 작기 때문에 운동빈도별 Light sleep % 그룹간 데이터의 유의한 차이가 존재한다.

---

### 첫번째 : 운동빈도별 Sleep efficiency

- 정규성 검정


```{python}
## Sleep efficiency와 운동빈도 정규성 검정 그래프
fig, axes = plt.subplots(2, 3, figsize=(15, 8))
axes = axes.flatten()
for i in range(6):
    sns.kdeplot(
        df[df['Exercise frequency'] == i]['Light sleep percentage'].dropna(),
        ax=axes[i],
        fill=True,
        color=sns.color_palette("tab10")[i],
    )
    axes[i].set_title(f"Exercise {i}")
    axes[i].set_xlim(0, 70)
    axes[i].grid(True, linestyle='--', alpha=0.3)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

```

```{python}
Ef_0_e = shapiro(Ef_0['Sleep efficiency'])
Ef_1_e = shapiro(Ef_1['Sleep efficiency'])
Ef_2_e = shapiro(Ef_2['Sleep efficiency'])
Ef_3_e = shapiro(Ef_3['Sleep efficiency'])
Ef_4_e = shapiro(Ef_4['Sleep efficiency'])
Ef_5_e = shapiro(Ef_5['Sleep efficiency'])

# print('운동 0번과 수면 효율 정규성 검정', Ef_0_e.pvalue )
# print('운동 1번과 수면 효율 정규성 검정', Ef_1_e.pvalue )
# print('운동 2번과 수면 효율 정규성 검정', Ef_2_e.pvalue )
# print('운동 3번과 수면 효율 정규성 검정', Ef_3_e.pvalue )
# print('운동 4번과 수면 효율 정규성 검정', Ef_4_e.pvalue )
# print('운동 5번과 수면 효율 정규성 검정', Ef_5_e.pvalue )
# print("모든값이 매우 작은값이다, 즉 귀무가설을 기각하고 정규분포를 따르지 않는다.")
```


| 검정 항목            | 귀무가설(H₀)                         | p-value    | 해석                 | 가정 만족 여부 |
|---------------------|------------------------------------|------------|----------------------|----------------|
| 운동 횟수 0번        | 이 변수는 정규분포를 따른다.            | 0.0015     | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 1번        | 이 변수는 정규분포를 따른다.            | 4.67e-05   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 2번        | 이 변수는 정규분포를 따른다.            | 4.51e-05   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 3번        | 이 변수는 정규분포를 따른다.            | 4.93e-08   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 4번        | 이 변수는 정규분포를 따른다.            | 3.82e-07   | 정규분포를 따르지 않는다. | ❌            |
| 운동 횟수 5번        | 이 변수는 정규분포를 따른다.            | 0.0001     | 정규분포를 따르지 않는다. | ❌            |


---



- 유의성 검정

```{python}
result_k2 = kruskal(Ef_0['Sleep efficiency'], Ef_1['Sleep efficiency']
                 ,Ef_2['Sleep efficiency'],Ef_3['Sleep efficiency']
                 ,Ef_4['Sleep efficiency'],Ef_5['Sleep efficiency']) 
# print('운동횟수에 따른 Light sleep 유의성 검정 : ', result_k2.pvalue)
# print('pvalue 값이 매우 작기 때문에 그룹간 유의한 차이가 있다.')
```

- **Kruskal-Wallis H 검정 사용**
    - 크루스칼-왈리스 검정 P_value = 5.757e-08
    - P_value가 매우 작기 때문에 운동빈도별 sleep efficiency 그룹간 데이터의 유의한 차이가 존재한다.

---

### 두번째 : 흡연 여부별 Light sleep % 


```{python}
smokers = df[df['Smoking status']=='Yes']
nonsmokers = df[df['Smoking status']=='No']

smokers["Sleep efficiency"].mean()
nonsmokers["Sleep efficiency"].mean()


# 흡연여부 및 Light sleep간 정규성 검정
smokers["Light sleep percentage"].mean()
nonsmokers["Light sleep percentage"].mean()
sns.kdeplot(smokers['Light sleep percentage'], label='Smoker', shade=True)
sns.kdeplot(nonsmokers['Light sleep percentage'], label='Non-smoker', shade=True)
plt.title("Smoker and Non_Smoker")
plt.legend()
plt.show()
# 그림으로 그려보면 정규분포를 따르지 않는것을 알 수 있다.
```


```{python}
from scipy.stats import shapiro
result1 = shapiro(smokers['Light sleep percentage'])
result2 = shapiro(nonsmokers['Light sleep percentage'])
# print('smoker pvalue : ', result1.pvalue)
# print('non_smoker pvalue : ', result2.pvalue)
# print('샤피로 윌크 검정 결과 귀무가설 기각 즉, 정규성을 따르지 않는다')

```

흡연자와 비흡연자 모두 정규성을 따르지 않는것을 알 수 있다.

```{python}
# 흡연 여부별 Light sleep의 유의성 검정
from scipy.stats import mannwhitneyu
result = mannwhitneyu(smokers['Light sleep percentage'], nonsmokers['Light sleep percentage'], alternative='two-sided')
# print('Light_pvalue : ', result.pvalue.round(5))
# print('만휘트니 검정결과 p_value 0.00138. 따라서 흡연자와 비흡연자간의 수면 효율 데이터에 유의한 차이가 존재한다.')
```

- **두번째 : 흡연 여부별 Light sleep % 정규성, 유의성 검정**
    - 흡연자 일 때    P_value = 7.889e-14
    - 비흡연자 일 때  P_value = 2.846e-23
    - 샤피로 윌크 검정 결과 둘다 귀무가설 기각, 즉 정규성을 따르지 않는다.<br>

    - 만 휘트니 P_value = 9.388e-09
    - P_value가 매우 작기 때문에 흡연자와 비흡연자간 데이터의 유의한 차이가 존재한다.


---

### 두번째 : 흡연 여부별 Sleep efficiency

```{python}
# 흡연여부 및 Sleep efficiency간 정규성 검정
sns.kdeplot(smokers['Sleep efficiency'], label='Smoker', shade=True)
sns.kdeplot(nonsmokers['Sleep efficiency'], label='Non-smoker', shade=True)
plt.title("Distribution of Sleep Efficiency by Smoking Status")
plt.xlabel("Sleep Efficiency")
plt.ylabel("Density")
plt.legend()
plt.show()
# 그림으로 그려보면 정규분포를 따르지 않는것을 알 수 있다.
```

```{python}
# 흡연 여부별 Sleep efficiency의 정규성 검정
from scipy.stats import shapiro
result1 = shapiro(smokers['Sleep efficiency'])
result2 = shapiro(nonsmokers['Sleep efficiency'])
# print('pvalue : ', result1.pvalue)
# print('pvalue : ', result2.pvalue)
# print('샤피로 윌크 검정 결과 귀무가설 기각 즉, 정규성을 따르지 않는다')
```


```{python}
# 흡연 여부별 Sleep efficiency의 유의성 검정
from scipy.stats import mannwhitneyu
result = mannwhitneyu(smokers['Sleep efficiency'], nonsmokers['Sleep efficiency'], alternative='two-sided')
# print("p-value:", result.pvalue)
# print('만휘트니 검정결과 p_value 매우작다. 따라서 흡연자와 비흡연자간의 수면 효율 데이터에 유의한 차이가 존재한다.')

```

- **흡연 여부별 Sleep efficiency 정규성, 유의성 검정 결과**
    - 흡연자 일 때    P_value = 1.008e-10
    - 비흡연자 일 때  P_value = 1.245e-09
    - 샤피로 윌크 검정 결과 둘다 귀무가설 기각, 즉 정규성을 따르지 않는다.<br>

    - 만 휘트니 P_value = 9.388e-09
    - P_value가 매우 작기 때문에 흡연자와 비흡연자간 데이터의 유의한 차이가 존재한다.

---

### 세번째 : 음주 여부별 Light sleep %

```{python}
# 2. Alcohol Group 컬럼 생성 (0.0 vs Other)
def alcohol_binary_group(val):
    if val == 0.0:
        return '0.0'
    else:
        return 'Other'
df['Alcohol consumption'].unique()
df['Alcohol Binary Group'] = df['Alcohol consumption'].apply(alcohol_binary_group)
# 취한 사람과 안취한 사람간의 데이터 구분

non_drink = df[df['Alcohol Binary Group'] == '0.0' ]
drink =  df[df['Alcohol Binary Group'] == 'Other' ]

# 알콜 기준 light sleep percentage

# 2. Alcohol 그룹 나누기: 0.0 vs Other
def alcohol_binary_group(val):
    if val == 0.0:
        return '0.0'
    else:
        return 'Other'

df['Alcohol Binary Group'] = df['Alcohol consumption'].apply(alcohol_binary_group)

# 3. 그룹별 평균 Light sleep percentage 계산
light_sleep_means = df.groupby('Alcohol Binary Group')['Light sleep percentage'].mean()

```

```{python}
# 알콜 기준 light sleep percentage 정규성 검증 
sns.kdeplot(drink['Light sleep percentage'], label='drink', shade=True)
sns.kdeplot(non_drink['Light sleep percentage'], label='non_drink', shade=True)
plt.title("Drink and Non_Drink")
plt.legend()
plt.show()
```

```{python}

# 알콜 여부 기준 Sleep_Efficiency 샤피로 검정
result1 = shapiro(drink['Light sleep percentage'])
result2 = shapiro(non_drink['Light sleep percentage'])
# print('pvalue : ', result1.pvalue)
# print('pvalue : ', result2.pvalue)
# print('샤피로 윌크 검정 결과 귀무가설 기각 즉, 정규성을 따르지 않는다')
```

```{python}

# 알콜 여부 기준 Sleep_Efficiency 유의성 검정
result = mannwhitneyu(drink['Light sleep percentage'], non_drink['Light sleep percentage'], alternative='two-sided')
# print("p-value:", result.pvalue)
# print('만휘트니 검정결과 p_value 매우작다. 따라서 흡연자와 비흡연자간의 수면 효율 데이터에 유의한 차이가 존재한다.')

```

- **음주 여부별 Light sleep % 정규성, 유의성 검정 결과**
    - 음주 했을 때    P_value = 1.432e-15
    - 음주 안 했을 때 P_value = 9.132e-23
    - 샤피로 윌크 검정 결과 둘다 귀무가설 기각, 즉 정규성을 따르지 않는다.<br>

    - 만 휘트니 P_value = 7.948e-11
    - P_value가 매우 작기 때문에 흡연자와 비흡연자간 데이터의 유의한 차이가 존재한다.

---

### 세번째 : 음주 여부별 Sleep efficiency

```{python}

# 알콜 여부 기준 Sleep_Efficiency 정규성 검증 
sns.kdeplot(drink['Sleep efficiency'], label='drink', shade=True)
sns.kdeplot(non_drink['Sleep efficiency'], label='non_drink', shade=True)
plt.title("Drink and Non_Drink")
plt.legend()
plt.show()
```

```{python}

# 알콜 여부 기준 Sleep_Efficiency 샤피로 검정
result1 = shapiro(drink['Sleep efficiency'])
result2 = shapiro(non_drink['Sleep efficiency'])
# print('pvalue : ', result1.pvalue)
# print('pvalue : ', result2.pvalue)
# print('샤피로 윌크 검정 결과 귀무가설 기각 즉, 정규성을 따르지 않는다')
```

```{python}

# 알콜 여부 기준 Sleep_Efficiency 유의성 검정
result = mannwhitneyu(drink['Sleep efficiency'], non_drink['Sleep efficiency'], alternative='two-sided')
# print("p-value:", result.pvalue)
# print('만휘트니 검정결과 p_value 매우작다. 따라서 흡연자와 비흡연자간의 수면 효율 데이터에 유의한 차이가 존재한다.')
```

- **음주 여부별 Sleep efficiency 정규성, 유의성 검정 결과**
    - 음주 했을 때    P_value = 1.522e-07
    - 음주 안 했을 때 P_value = 1.626e-12
    - 샤피로 윌크 검정 결과 둘다 귀무가설 기각, 즉 정규성을 따르지 않는다.<br>

    - 만 휘트니 P_value = 8.686e-16
    - P_value가 매우 작기 때문에 흡연자와 비흡연자간 데이터의 유의한 차이가 존재한다.

---

### 네번째 : 카페인 여부별 카이제곱 검정

```{python}

## 카페인 변수 넣었던 이유
# 파생 변수 생성 (카이제곱용 이진화)
df['High_Caffeine'] = (df['Caffeine consumption'] > 3).astype(int)      # 3단위 초과 → 고카페인
df['Short_Sleep'] = (df['Sleep duration'] < 6).astype(int)              # 6시간 미만 → 짧은 수면
df['High_Alcohol'] = (df['Alcohol consumption'] > 3).astype(int)        # 3단위 초과 → 고알콜
df['Low_Efficiency'] = (df['Sleep efficiency'] < 0.85).astype(int)      # 85% 미만 → 수면 효율 낮음
df['High_Exercise'] = (df["Exercise frequency"] > 2 ).astype(int)       # 3번 이상 -> 많은 운동량
df['Low_light_sleep'] = (df['Light sleep percentage'] < 25).astype(int)

# 카이제곱 검정할 변수쌍 정의
pairs = [
    ('High_Caffeine', 'Short_Sleep'),
    ('High_Caffeine', 'High_Alcohol'),
    ('High_Caffeine', 'Low_Efficiency'),
    ('High_Caffeine', 'High_Exercise'),
    ('High_Caffeine', 'Low_light_sleep')
]

# 카이제곱 검정 실행
results = []

for var1, var2 in pairs:
    table = pd.crosstab(df[var1], df[var2])
    stat, p, dof, expected = chi2_contingency(table)
    results.append({
        "Variable 1": var1,
        "Variable 2": var2,
        "p-value": round(p, 5)
    })

# 결과 보기
results_df = pd.DataFrame(results)
# print(results_df)
```


| 변수 1         | 변수 2           | p-value | 유의성 | 해석 요약                     |
|----------------|------------------|---------|--------|-------------------------------|
| High_Caffeine  | Short_Sleep      | 1.00000 | ❌     | 관계 없음                    |
| High_Caffeine  | High_Alcohol     | 0.03796 | ✅     | 고카페인과 고알콜은 관련 있음 |
| High_Caffeine  | Low_Efficiency   | 0.30201 | ❌     | 유의미한 관계 아님            |
| High_Caffeine  | High_Exercise    | 0.00000 | ✅     | 카페인 많을수록 운동도 많음    |
| High_Caffeine  | Low_light_sleep  | 0.74428 | ❌     | 관계 없음                    |


- **카페인 여부별 카이제곱 검정 결과**  
    Short_Sleep, Low_Efficiency, Low_light_sleep은 귀무가설 채택 즉,
    카페인과 세변수는 독립적이다.

    반대로 High_Alcohol, High_Excercise는 귀무가설 기각 즉,
    카페인과 두변수는 서로 연관이 있다.

---

## 모델 검정

- **모델 선정 과정**

    - **step 1. 카페인 포함한 모델링**  
    정규성, 등분산성, QQplot을 통해 설명력을 가지는 모델인지 판단.

    - **step 2. aic-score를 통해 만든 최적 모델링**  
    정규성, 등분산성, QQplot을 통해 설명력을 가지는 모델인지 판단.

    - **step 3. 카페인을 포함한 모델 vs 카페인을 미포함한 모델 (최종 모델)**  
    → `anova`를 통해 두 모델을 비교하여 `최종 모델 선정`

---

- **step 1. 카페인 포함한 모델링** 
    - 독립변수 : 'Light sleep percentage', 'Smoking status' ,'Alcohol consumption','Awakenings', 'Exercise frequency', `'Caffeine consumption'`
    - 종속변수 : 'Sleep efficiency'
    - `Breusch-Pagan` 은 가장 직관적이고 널리 사용되는 등분산성 검증으로, `잔차가 특정 변수에 의해 달라지는지` 확인하는데 유리함.
    -> 해당 통계량이 `유의미하게 크면 이분산성 존재`라고 판단.

---

- **<모델링 결과>**
    - 모델 주요 결과 요약표

| 항목             | 값            | 해석 요약 |
|------------------|----------------|------------|
| **R-squared**    | 0.802          | 설명력 80.2% |
| **Adj. R-squared** | 0.800        | 변수 수 반영 설명력 |
| **F-statistic**  | 361.3        | 모델 전체 유의 |
| **Prob(F-statistic)** | 2.57e-154 | p < 0.001 → 유의 |
| **AIC**          | -1247          | 모델 비교용 (낮을수록 좋음) |
| **BIC**          | -1222          | 모델 비교용 (낮을수록 좋음) |



    - 주요 변수 계수 (p < 0.05)

| 변수                   | 계수 (coef) | p-value | 해석 요약 |
|------------------------|-------------|---------|-----------|
| Light sleep %          | -0.0056     | 0.000   | 수면효율 감소 (음영향) |
| Alcohol consumption    | -0.0075     | 0.000   | 음주 → 효율 저하 |
| Awakenings             | -0.0337     | 0.000   | 자주 깨면 ↓ |
| Exercise frequency     | +0.0043     | 0.037   | 운동 ↑ → 효율 ↑ |
| Yes                    | -0.0444     | 0.000   | 흡연 O → 효율 ↓|
| ~~Caffeine consumption~~ | 0.00007     | 0.493   | ❌ 유의하지 않음 |


---

- <모델링 검증 결과>
    - Q-Q Plot에서 극단값이 정규선에서 벗어나며 정규성 가정이 일부 위배됨
    - 잔차와 예측값 간 패턴에서 이분산성과 선형성 위반이 동시에 확인됨
    - 따라서 이 회귀모형은 잔차 가정을 충족하지 못하며 보정이 필요함

| 검정 항목            | 귀무가설(H₀)                      | p-value    | 해석                 | 가정 만족 여부 |
|---------------------|----------------------------------|------------|----------------------|----------------|
| Shapiro-Wilk Test   | 잔차는 정규분포를 따른다         | 0.00028    | 정규성 위반 (기각)   | ❌            |
| Breusch-Pagan Test  | 오차항은 등분산성을 가진다       | 0.0416    | 이분산성 존재 (기각) | ❌            |

    
```{python}
#| echo: False

# 원래 수치형 변수들
num_vars = ['Light sleep percentage', 'Alcohol consumption','Awakenings', 'Exercise frequency', 'Caffeine consumption']

# 범주형 변수 → 더미로 변환
smoking_dummy = pd.get_dummies(df['Smoking status'], drop_first=True)

# 최종 X 구성 (수치형 + 더미 합치기)
X = pd.concat([df[num_vars], smoking_dummy], axis=1)
X = X.astype(float)
X = X.dropna()
y = df['Sleep efficiency']
X_const = sm.add_constant(X)

# 회귀 모델 적합
model = sm.OLS(y, X_const).fit()

# 모델 결과 출력
# print(model.summary())

# 정규성 검정 (Shapiro-Wilk)
shapiro_stat, shapiro_p = shapiro(model.resid)
# print(f"\nShapiro-Wilk Test (잔차 정규성 검정):\nStatistic = {shapiro_stat:.4f}, p-value = {shapiro_p:.5f}")

# 등분산성 검정 (Breusch-Pagan)
# 변수로 다양할때 등분산성 검정은 Breusch-Pegan 사용
bp_test = het_breuschpagan(model.resid, X_const)
bp_p = bp_test[1]
# print(f"\nBreusch-Pagan Test (잔차 등분산성 검정):\np-value = {bp_p:.5f}")

```

::: {.columns}

:::{.column width="50%"}

```{python}
#| echo: false
#| fig-align: center
#| fig-width: 5
#| fig-height: 4

# Q-Q Plot 그리기
plt.figure(figsize=(5, 5))
sm.qqplot(model.resid, line='45', fit=True)
_=plt.title("Q-Q Plot of Residuals (Based on Scatter Pattern)")
plt.grid(True)
plt.tight_layout()
plt.show()

# 잔차분산성 검증
plt.scatter(model.fittedvalues, model.resid)
plt.axhline(0, color='red')
_=plt.title("Fitted vs Residuals")
```

:::

:::

---

- **step 2. aic-score를 통해 만든 최적 모델링**
    - 독립변수 : 'Light sleep percentage', 'Smoking status','Alcohol consumption','Awakenings', 'Exercise frequency'
    - 종속변수 : 'Sleep efficiency'
    - `aic-score` 를 통해 최적의 변수를 찾아 해당 변수로 모델 진행
    -`Breusch-Pagan` 을 통해 이분산성 확인 진행 

- <모델링 결과>
    - 모델 주요 결과 요약표

| 항목                 | 값           | 해석 요약                       |
|----------------------|--------------|----------------------------------|
| **R-squared**        | 0.802        | 설명력 80.2%                     |
| **Adj. R-squared**   | 0.800        | 변수 수 반영한 설명력           |
| **F-statistic**      | 361.3        | 모델 전체 유의                  |
| **Prob(F-statistic)**| 2.57e-154    | **p < 0.001**, 매우 유의함      |
| **AIC**              | -1247        | 모델 비교용 지표 (낮을수록 좋음) |
| **BIC**              | -1222        | 모델 비교용 지표 (낮을수록 좋음) |

    - 주요 변수 계수 (p < 0.05)

| 변수                   | 계수 (coef) | p-value | 해석 요약                    |
|------------------------|-------------|---------|------------------------------|
| Light sleep %          | -0.0056     | 0.000   | 수면효율 감소에 유의한 영향 |
| Alcohol consumption    | -0.0075     | 0.000   | 음주 → 효율 저하             |
| Awakenings             | -0.0337     | 0.000   | 자주 깰수록 효율 하락        |
| Exercise frequency     | +0.0043     | 0.037   | 운동 ↑ → 수면효율 증가       |
| Yes     | -0.0444     | 0.000   | 흡연 O → 수면효율 저하       |


---

- <모델링 검증 결과>
    - 잔차가 정규분포를 따르지 않음
    - 하지만 회귀계수 자체가 나쁜 건 아님 예측력 자체에는 큰 영향 없음
    - 등분산성에서는 잔차의 분산성이 일정하지 않음 -> 이분산성 존재
    - 테스트 데이터가 없으므로 rsquared_adj를 확인한 결과 나쁘지 않은 설명력을 가짐.

| 검정 항목            | 귀무가설(H₀)                      | p-value    | 해석                   |
|----------------------|----------------------------------|------------|------------------------|
| Shapiro-Wilk Test    | 잔차는 정규분포를 따른다         | 0.00033    | ❌ 정규성 위반 (기각)   |
| Breusch-Pagan Test   | 오차항은 등분산성을 가진다       | 0.03395    | ❌ 이분산성 존재 (기각) |


```{python}
#| echo: False
#| fig-width: 5
#| fig-height: 4
#| fig-align: center
# 원래 수치형 변수들
num_vars = ['Light sleep percentage', 'Alcohol consumption','Awakenings', 'Exercise frequency', 'Caffeine consumption']

# 범주형 변수 → 더미로 변환
smoking_dummy = pd.get_dummies(df['Smoking status'], drop_first=True)

# 최종 X 구성 (수치형 + 더미 합치기)
X = pd.concat([df[num_vars], smoking_dummy], axis=1)
X = X.astype(float)
X = X.dropna()
y = df['Sleep efficiency']
names = X.columns.tolist()

# AIC 계산 함수 (오류 없는 버전)
def aic_score(estimator, X_subset_np, y_np): 
    X_const = sm.add_constant(X_subset_np)
    model = sm.OLS(y_np, X_const).fit()
    return -model.aic  # AIC가 낮을수록 좋으므로 음수 반환

# 모델 정의
lr = LinearRegression()

# SFS (AIC 기준 forward selection)
sfs = SFS(estimator=lr,
          k_features=(1, len(X.columns)),
          forward=True,
          floating=False,
          scoring=aic_score,
          cv=0,
          verbose=1)

# 피팅
sfs.fit(X.values, y.values)

# 선택된 변수 추출
selected_indices = list(sfs.k_feature_idx_)
selected_features = [names[i] for i in selected_indices]
print("최종 선택된 변수:", selected_features)

# 최종 모델 학습 (statsmodels OLS)
X_selected = sm.add_constant(X[selected_features])
final_model = sm.OLS(y, X_selected).fit()

# 결과 출력
# print(final_model.summary())# 원래 수치형 변수들


### 최종모델 검증하는 방법
# 1. 정규성 (Shapiro-Wilk)
shapiro_stat, shapiro_p = shapiro(final_model.resid)

# 2. 등분산성 (Breusch-Pagan)
bp_test = het_breuschpagan(final_model.resid, X_selected)
bp_p = bp_test[1]

# 3. Q-Q Plot
# plt.figure(figsize=(5, 4))  # QMD에서도 작동함!
# sm.qqplot(final_model.resid, line='45', fit=True)
# plt.title("Q-Q Plot of Residuals")
# plt.tight_layout()
# plt.show()

### (해석)
# 잔차는 대체로 정규성을 만족하지만, 극단값 구간에서는 일부 왜곡이 나타난다.
# 이는 회귀계수의 정확도에 큰 영향을 주지는 않으나,
# 정밀한 신뢰구간 해석이나 극단값에 민감한 분석에서는 주의가 필요하다



# # 4. 테스트 데이터 없으므로 rsquared_adj 확인인
# print(final_model.rsquared_adj)

# # 4. 결과 출력
# print("선택된 변수:", selected_features)
# print(f"Shapiro-Wilk p-value (정규성): {shapiro_p:.5f}")
# print(f"Breusch-Pagan p-value (등분산성): {bp_p:.5f}")
# print("회귀 요약:")
# print(final_model.summary())



# - 이 모델은 이분산성이 존재해서 통계적 해석(p값, t검정)은 신뢰하기 어려움.왜냐하면 수면 효율성, rem, deep, light sleep은 매우 서로 연관성이 높기 때문!
#     - 예측 성능이 괜찮다면 예측용으로는 여전히 활용 가능함.
#     - 군집분석, 주성분 분석, kluster 등을 통해 모델을 반영하거나 혹은 데이터 변환이 필요해보임

```



::: {.columns}

:::{.column width="50%"}

```{python}
#| echo: false
#| fig-align: center
#| fig-width: 5
#| fig-height: 4

# Q-Q Plot 그리기

sm.qqplot(final_model.resid, line='45', fit=True)
plt.title("Q-Q Plot of Residuals")
plt.grid(True)
plt.tight_layout()
plt.show()


# 잔차분산성 검증
plt.scatter(final_model.fittedvalues, final_model.resid)
plt.axhline(0, color='red')
plt.title("Fitted vs Residuals")
```

:::

:::


---

- **step 3. 카페인을 포함한 모델 vs 카페인을 미포함한 모델 (최적 모델)** 

    - 추가된 변수는 기존 모델 대비 수면 효율 예측에 통계적으로 유의한 기여를 하지 않았으며,두 모델 간 차이는 F(1, 446) = 0.28, p = 0.5964로 나타남
    - `카페인을 미포함한 모델`이 충분한 설명력을 유지함을 의미함.


| 모델 | df | SSR       | Δdf | ΔSSR     | F      | p-value |
|------|----|-----------|-----|----------|--------|---------|
| M1   | 446 | 1.633088   | –   | –        | –      | –       |
| M2   | 445 | 1.632058   | 1   | 0.0010   | 0.2808  | 0.596438   |



# 결론

## 수면효율 향상을 위해 어떻게 해야할까?

- 🏃‍♂️ **운동**: 규칙적인 운동은 수면의 질을 향상시킬 수 있음

<br>

- 🍷 **음주**: 음주는 일시적인 졸림을 유도하지만, 깊은 수면을 방해함

<br>

- 🚬 **흡연**: 니코틴은 자극제로 작용하여 수면을 방해함

<br>

- ☕ **카페인**: 유의미한 상관이 없다

## LS미래원은 수면효율을 위해 무엇을 해야 하며 우리는 무엇을 해야 하는가?

- 🏫 **LS미래원**: 커리큘럼에 체육활동 추가

<br>

- 👩‍🎓 **교육생**: 흡연 자제, 규칙적인 운동


## 통계적 한계





:::{.columns}

::: {.column width="50%"}

```{python}
plt.figure(figsize=(10, 7))
sns.heatmap(corr_matrix, 
            annot=True,         # 셀 안에 숫자 표시
            fmt=".2f",          # 소수점 둘째자리까지
            cmap="coolwarm",    # 색상 맵
            square=True, 
            linewidths=0.5)
plt.title("Correlation matrix heatmap of numerical features")
plt.tight_layout()
plt.grid(False)
plt.show()
```

<br><br>
![](12.png){width=100%}

<br><br>

![](34.png){width=100%}

:::

::: {.column width="50%"}


<br>
1. 📉 **다중공선성(Multicollinearity)**  
   - `Light sleep`과 `Deep sleep`가 서로 강하게 연관되어 있음  
   - 독립 변수들 간의 상관이 높아 회귀 모형이 **불안정**해질 수 있음

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
2. 📊 **비정규 분포 + 이분포 구조**  
   - 독립 변수들이 **정규성을 따르지 않음**  
   - 밀도 분포에서 **두 개의 봉우리(이봉성)**가 관찰됨  
   - 이는 **데이터 내부에 하위 집단이 존재**할 가능성을 시사하며  
     👉 **이분화 분석** 또는 **주성분 분석**이 더 적절할 수 있음

:::
:::